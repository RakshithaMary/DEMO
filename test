from pyspark.sql import functions as F

# 1. Total count of Unknown prospect_fi_id
unknown_total = (
    df.filter(F.col("prospect_fi_id") == "Unknown")
      .count()
)

print("Total Unknown prospect_fi_id:", unknown_total)


# 2. Distribution by payment_product_nm
unknown_dist = (
    df.filter(F.col("prospect_fi_id") == "Unknown")
      .groupBy("payment_product_nm")
      .agg(F.count("*").alias("unknown_count"))
      .orderBy(F.desc("unknown_count"))
)

unknown_dist.show(100, truncate=False)
