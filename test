from pyspark.sql import functions as F

jan_sel = jan_df.select(
    F.col("client_id").alias("jan_client_id"),
    F.col("account_number").alias("account_number"),
    F.col("account_product_id").alias("account_product_id"),
    F.col("balance").alias("jan_balance")
)

dec_sel = dec_df.select(
    F.col("client_id").alias("dec_client_id"),
    F.col("account_number").ali
as("account_number"),
    F.col("account_product_id").alias("account_product_id"),
    F.col("balance").alias("dec_balance")
)




joined_df = (
    balance_df.alias("b")
    .join(
        jan_sel.alias("j"),
        on=["account_number", "account_product_id", "client_id"],
        how="left"
    )
    .join(
        dec_sel.alias("d"),
        on=["account_number", "account_product_id", "client_id"],
        how="left"
    )
)





final_df = joined_df.withColumn(
    "monthly_balance_diff",
    F.col("jan_balance") - F.col("dec_balance")
)




final_df = final_df.withColumn(
    "diff_vs_account_balance",
    F.col("monthly_balance_diff") - F.col("account_balance")
)



final_df.select(
    "client_id",
    "account_number",
    "account_product_id",
    "account_balance",
    "jan_balance",
    "dec_balance",
    "monthly_balance_diff",
    "diff_vs_account_balance"
).show(50, truncate=False)

